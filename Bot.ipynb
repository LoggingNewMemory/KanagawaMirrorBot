{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LoggingNewMemory/MirrorBot/blob/main/Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5014732c",
      "metadata": {
        "id": "5014732c"
      },
      "source": [
        "**Google Colab Mirrorbot** <br />\n",
        "By: Kanagawa Yamada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48502716",
      "metadata": {
        "id": "48502716"
      },
      "outputs": [],
      "source": [
        "# Mirror Bot for Google Colab with Download Speed Indicator and Preserved Filenames\n",
        "# Install required packages\n",
        "!pip install requests beautifulsoup4 pyrogram tgcrypto\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import asyncio\n",
        "import time\n",
        "from urllib.parse import urlparse, unquote\n",
        "from pathlib import Path\n",
        "import zipfile\n",
        "import tarfile\n",
        "from google.colab import drive, files\n",
        "from IPython.display import display, HTML\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "class MirrorBot:\n",
        "    def __init__(self):\n",
        "        self.download_dir = \"/content/downloads\"\n",
        "        self.drive_dir = \"/content/drive/MyDrive/MirrorBot\"\n",
        "        self.mount_drive()\n",
        "        self.setup_directories()\n",
        "\n",
        "    def mount_drive(self):\n",
        "        \"\"\"Mount Google Drive\"\"\"\n",
        "        try:\n",
        "            drive.mount('/content/drive')\n",
        "            print(\"‚úÖ Google Drive mounted successfully\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error mounting drive: {e}\")\n",
        "\n",
        "    def setup_directories(self):\n",
        "        \"\"\"Create necessary directories\"\"\"\n",
        "        os.makedirs(self.download_dir, exist_ok=True)\n",
        "        os.makedirs(self.drive_dir, exist_ok=True)\n",
        "        print(f\"üìÅ Directories created: {self.download_dir}, {self.drive_dir}\")\n",
        "\n",
        "    def get_filename_from_response(self, response):\n",
        "        \"\"\"Extract filename from response headers (Content-Disposition)\"\"\"\n",
        "        content_disposition = response.headers.get('Content-Disposition', '')\n",
        "        if content_disposition:\n",
        "            # Try to find filename in Content-Disposition header\n",
        "            filename_match = re.search(r'filename[*]?=([^;]+)', content_disposition)\n",
        "            if filename_match:\n",
        "                filename = filename_match.group(1).strip('\\'\"')\n",
        "                # Handle RFC 5987 encoded filenames\n",
        "                if filename.startswith(\"UTF-8''\"):\n",
        "                    filename = unquote(filename[7:])\n",
        "                return filename\n",
        "        return None\n",
        "\n",
        "    def get_filename_from_url(self, url, response=None):\n",
        "        \"\"\"Extract filename from URL or response headers\"\"\"\n",
        "        # First try to get filename from response headers\n",
        "        if response:\n",
        "            header_filename = self.get_filename_from_response(response)\n",
        "            if header_filename:\n",
        "                return header_filename\n",
        "\n",
        "        # Parse URL to get filename\n",
        "        parsed = urlparse(url)\n",
        "        filename = os.path.basename(unquote(parsed.path))\n",
        "\n",
        "        # If we got a proper filename from URL, use it\n",
        "        if filename and not filename.startswith('.') and len(filename) > 0:\n",
        "            # Remove query parameters if they got included\n",
        "            filename = filename.split('?')[0].split('#')[0]\n",
        "            if filename:\n",
        "                return filename\n",
        "\n",
        "        # Try to extract from query parameters (common in download links)\n",
        "        from urllib.parse import parse_qs\n",
        "        query_params = parse_qs(parsed.query)\n",
        "        for param in ['filename', 'file', 'name', 'title']:\n",
        "            if param in query_params and query_params[param][0]:\n",
        "                potential_filename = query_params[param][0]\n",
        "                if potential_filename and not potential_filename.startswith('.'):\n",
        "                    return potential_filename\n",
        "\n",
        "        # Last resort: try to extract from the full URL path\n",
        "        path_parts = [part for part in parsed.path.split('/') if part]\n",
        "        if path_parts:\n",
        "            last_part = unquote(path_parts[-1])\n",
        "            if last_part and not last_part.startswith('.') and len(last_part) > 0:\n",
        "                return last_part.split('?')[0].split('#')[0]\n",
        "\n",
        "        # Final fallback: generate a name based on domain and hash\n",
        "        domain = parsed.netloc.replace('www.', '') if parsed.netloc else 'download'\n",
        "        return f\"{domain}_{hash(url) % 10000}\"\n",
        "\n",
        "    def sanitize_filename(self, filename):\n",
        "        \"\"\"Sanitize filename to be safe for filesystem\"\"\"\n",
        "        # Replace unsafe characters\n",
        "        unsafe_chars = '<>:\"/\\\\|?*'\n",
        "        for char in unsafe_chars:\n",
        "            filename = filename.replace(char, '_')\n",
        "\n",
        "        # Limit length\n",
        "        if len(filename) > 200:\n",
        "            name, ext = os.path.splitext(filename)\n",
        "            filename = name[:200-len(ext)] + ext\n",
        "\n",
        "        return filename\n",
        "\n",
        "    def format_speed(self, bytes_per_second):\n",
        "        \"\"\"Format download speed\"\"\"\n",
        "        for unit in ['B/s', 'KB/s', 'MB/s', 'GB/s']:\n",
        "            if bytes_per_second < 1024:\n",
        "                return f\"{bytes_per_second:.1f} {unit}\"\n",
        "            bytes_per_second /= 1024\n",
        "        return f\"{bytes_per_second:.1f} TB/s\"\n",
        "\n",
        "    def estimate_time_remaining(self, downloaded, total_size, speed):\n",
        "        \"\"\"Estimate remaining download time\"\"\"\n",
        "        if speed == 0 or total_size == 0:\n",
        "            return \"‚àû\"\n",
        "\n",
        "        remaining_bytes = total_size - downloaded\n",
        "        remaining_seconds = remaining_bytes / speed\n",
        "\n",
        "        if remaining_seconds < 60:\n",
        "            return f\"{int(remaining_seconds)}s\"\n",
        "        elif remaining_seconds < 3600:\n",
        "            return f\"{int(remaining_seconds // 60)}m {int(remaining_seconds % 60)}s\"\n",
        "        else:\n",
        "            hours = int(remaining_seconds // 3600)\n",
        "            minutes = int((remaining_seconds % 3600) // 60)\n",
        "            return f\"{hours}h {minutes}m\"\n",
        "\n",
        "    def download_file(self, url, custom_name=None):\n",
        "        \"\"\"Download file from URL with speed indicator and preserved filename\"\"\"\n",
        "        try:\n",
        "            print(f\"üîÑ Starting download: {url}\")\n",
        "\n",
        "            headers = {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "            }\n",
        "\n",
        "            # Make initial request to get headers\n",
        "            response = requests.get(url, headers=headers, stream=True)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            # Get filename - priority: custom_name > response headers > URL\n",
        "            if custom_name:\n",
        "                filename = custom_name\n",
        "            else:\n",
        "                filename = self.get_filename_from_url(url, response)\n",
        "\n",
        "            # Sanitize filename\n",
        "            filename = self.sanitize_filename(filename)\n",
        "            filepath = os.path.join(self.download_dir, filename)\n",
        "\n",
        "            # Handle duplicate filenames\n",
        "            if os.path.exists(filepath):\n",
        "                base, ext = os.path.splitext(filename)\n",
        "                counter = 1\n",
        "                while os.path.exists(filepath):\n",
        "                    new_filename = f\"{base}_{counter}{ext}\"\n",
        "                    filepath = os.path.join(self.download_dir, new_filename)\n",
        "                    counter += 1\n",
        "                filename = os.path.basename(filepath)\n",
        "\n",
        "            print(f\"üìÅ Saving as: {filename}\")\n",
        "\n",
        "            total_size = int(response.headers.get('content-length', 0))\n",
        "            downloaded = 0\n",
        "\n",
        "            # Speed calculation variables\n",
        "            start_time = time.time()\n",
        "            last_time = start_time\n",
        "            last_downloaded = 0\n",
        "            speed_samples = []\n",
        "            max_samples = 10  # Keep last 10 speed samples for smoothing\n",
        "\n",
        "            with open(filepath, 'wb') as file:\n",
        "                for chunk in response.iter_content(chunk_size=8192):\n",
        "                    if chunk:\n",
        "                        file.write(chunk)\n",
        "                        downloaded += len(chunk)\n",
        "\n",
        "                        current_time = time.time()\n",
        "                        time_elapsed = current_time - last_time\n",
        "\n",
        "                        # Calculate speed every 0.5 seconds for smooth updates\n",
        "                        if time_elapsed >= 0.5:\n",
        "                            bytes_in_interval = downloaded - last_downloaded\n",
        "                            current_speed = bytes_in_interval / time_elapsed if time_elapsed > 0 else 0\n",
        "\n",
        "                            # Add to speed samples for smoothing\n",
        "                            speed_samples.append(current_speed)\n",
        "                            if len(speed_samples) > max_samples:\n",
        "                                speed_samples.pop(0)\n",
        "\n",
        "                            # Calculate average speed\n",
        "                            avg_speed = sum(speed_samples) / len(speed_samples)\n",
        "\n",
        "                            # Update display\n",
        "                            if total_size > 0:\n",
        "                                progress = (downloaded / total_size) * 100\n",
        "                                eta = self.estimate_time_remaining(downloaded, total_size, avg_speed)\n",
        "                                print(f\"\\rüì• {progress:.1f}% | {self.format_speed(avg_speed)} | ETA: {eta} | {self.format_size(downloaded)}/{self.format_size(total_size)}\",\n",
        "                                      end='', flush=True)\n",
        "                            else:\n",
        "                                print(f\"\\rüì• {self.format_speed(avg_speed)} | {self.format_size(downloaded)} downloaded\",\n",
        "                                      end='', flush=True)\n",
        "\n",
        "                            last_time = current_time\n",
        "                            last_downloaded = downloaded\n",
        "\n",
        "            # Final statistics\n",
        "            total_time = time.time() - start_time\n",
        "            avg_speed = downloaded / total_time if total_time > 0 else 0\n",
        "\n",
        "            print(f\"\\n‚úÖ Downloaded: {filename}\")\n",
        "            print(f\"üìä Size: {self.format_size(downloaded)} | Time: {total_time:.1f}s | Avg Speed: {self.format_speed(avg_speed)}\")\n",
        "            return filepath\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Download failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def format_size(self, bytes):\n",
        "        \"\"\"Format file size\"\"\"\n",
        "        for unit in ['B', 'KB', 'MB', 'GB']:\n",
        "            if bytes < 1024:\n",
        "                return f\"{bytes:.1f} {unit}\"\n",
        "            bytes /= 1024\n",
        "        return f\"{bytes:.1f} TB\"\n",
        "\n",
        "    def extract_archive(self, filepath):\n",
        "        \"\"\"Extract compressed files\"\"\"\n",
        "        try:\n",
        "            extract_dir = os.path.splitext(filepath)[0]\n",
        "            os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "            print(f\"üì¶ Extracting archive...\")\n",
        "\n",
        "            if filepath.endswith(('.zip', '.jar')):\n",
        "                with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
        "                    zip_ref.extractall(extract_dir)\n",
        "            elif filepath.endswith(('.tar', '.tar.gz', '.tgz')):\n",
        "                with tarfile.open(filepath, 'r:*') as tar_ref:\n",
        "                    tar_ref.extractall(extract_dir)\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Not a supported archive format\")\n",
        "                return filepath\n",
        "\n",
        "            print(f\"‚úÖ Extracted to: {extract_dir}\")\n",
        "            return extract_dir\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Extraction failed: {e}\")\n",
        "            return filepath\n",
        "\n",
        "    def move_to_drive(self, filepath):\n",
        "        \"\"\"Move downloaded file to Google Drive\"\"\"\n",
        "        try:\n",
        "            filename = os.path.basename(filepath)\n",
        "            drive_path = os.path.join(self.drive_dir, filename)\n",
        "\n",
        "            print(f\"‚òÅÔ∏è Moving to Google Drive...\")\n",
        "\n",
        "            if os.path.isdir(filepath):\n",
        "                shutil.copytree(filepath, drive_path, dirs_exist_ok=True)\n",
        "            else:\n",
        "                shutil.copy2(filepath, drive_path)\n",
        "\n",
        "            print(f\"‚úÖ Moved to Drive: {drive_path}\")\n",
        "            return drive_path\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Failed to move to Drive: {e}\")\n",
        "            return None\n",
        "\n",
        "    def list_downloads(self):\n",
        "        \"\"\"List all downloaded files\"\"\"\n",
        "        print(\"\\nüìã Downloaded Files:\")\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "        total_files = 0\n",
        "        total_size = 0\n",
        "\n",
        "        for root, dirs, files in os.walk(self.download_dir):\n",
        "            level = root.replace(self.download_dir, '').count(os.sep)\n",
        "            indent = ' ' * 2 * level\n",
        "            if level == 0 and files:\n",
        "                print(f\"{indent}üìÅ {os.path.basename(root) or 'downloads'}/\")\n",
        "            elif level > 0:\n",
        "                print(f\"{indent}üìÅ {os.path.basename(root)}/\")\n",
        "\n",
        "            subindent = ' ' * 2 * (level + 1)\n",
        "            for file in files:\n",
        "                filepath = os.path.join(root, file)\n",
        "                size = os.path.getsize(filepath)\n",
        "                total_files += 1\n",
        "                total_size += size\n",
        "                print(f\"{subindent}üìÑ {file} ({self.format_size(size)})\")\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "        print(f\"üìä Total: {total_files} files, {self.format_size(total_size)}\")\n",
        "\n",
        "    def clear_downloads(self):\n",
        "        \"\"\"Clear download directory\"\"\"\n",
        "        try:\n",
        "            shutil.rmtree(self.download_dir)\n",
        "            os.makedirs(self.download_dir, exist_ok=True)\n",
        "            print(\"üóëÔ∏è Downloads cleared\")\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error clearing downloads: {e}\")\n",
        "\n",
        "    def mirror(self, url, extract=False, move_to_drive=True, custom_name=None):\n",
        "        \"\"\"Main mirror function\"\"\"\n",
        "        print(f\"üöÄ Mirror Bot Starting...\")\n",
        "        print(f\"üìÇ Download directory: {self.download_dir}\")\n",
        "        print(f\"‚òÅÔ∏è Drive directory: {self.drive_dir}\")\n",
        "        print(\"=\" * 60)\n",
        "\n",
        "        # Download file\n",
        "        filepath = self.download_file(url, custom_name)\n",
        "        if not filepath:\n",
        "            return None\n",
        "\n",
        "        # Extract if requested and it's an archive\n",
        "        if extract:\n",
        "            filepath = self.extract_archive(filepath)\n",
        "\n",
        "        # Move to Google Drive if requested\n",
        "        if move_to_drive:\n",
        "            drive_path = self.move_to_drive(filepath)\n",
        "            if drive_path:\n",
        "                print(f\"‚ú® Mirror completed! File saved to Drive\")\n",
        "                return drive_path\n",
        "\n",
        "        print(f\"‚ú® Mirror completed! File saved locally\")\n",
        "        return filepath\n",
        "\n",
        "# Initialize the mirror bot\n",
        "bot = MirrorBot()\n",
        "\n",
        "# Example usage functions\n",
        "def mirror_file(url, extract=False, move_to_drive=True, custom_name=None):\n",
        "    \"\"\"Mirror a file from URL\"\"\"\n",
        "    return bot.mirror(url, extract, move_to_drive, custom_name)\n",
        "\n",
        "def list_files():\n",
        "    \"\"\"List downloaded files\"\"\"\n",
        "    bot.list_downloads()\n",
        "\n",
        "def clear_files():\n",
        "    \"\"\"Clear all downloads\"\"\"\n",
        "    bot.clear_downloads()\n",
        "\n",
        "# Display usage instructions\n",
        "display(HTML(\"\"\"\n",
        "<div style=\"border: 2px solid #4CAF50; padding: 15px; border-radius: 10px; background-color: #f9f9f9;\">\n",
        "<h3>ü§ñ Enhanced Mirror Bot Ready! (With Preserved Filenames)</h3>\n",
        "<h4>New Features:</h4>\n",
        "<ul>\n",
        "<li>üìä Real-time download speed</li>\n",
        "<li>‚è±Ô∏è ETA (Estimated Time of Arrival)</li>\n",
        "<li>üìà Progress with detailed statistics</li>\n",
        "<li>üéØ Improved file listing with total stats</li>\n",
        "<li>‚ú® <strong>Preserves original filenames from downloads</strong></li>\n",
        "<li>üîß Smart filename detection from URLs and headers</li>\n",
        "<li>üõ°Ô∏è Handles duplicate filenames automatically</li>\n",
        "</ul>\n",
        "<h4>Usage Examples:</h4>\n",
        "<code>\n",
        "# Mirror a file (preserves original name)<br>\n",
        "mirror_file(\"https://example.com/LOS-GSI.zip\")<br>\n",
        "# Output: LOS-GSI.zip<br><br>\n",
        "\n",
        "# Mirror and extract archive<br>\n",
        "mirror_file(\"https://example.com/archive.zip\", extract=True)<br><br>\n",
        "\n",
        "# Mirror with custom name (overrides detection)<br>\n",
        "mirror_file(\"https://example.com/file.pdf\", custom_name=\"my_document.pdf\")<br><br>\n",
        "\n",
        "# Mirror without moving to Drive<br>\n",
        "mirror_file(\"https://example.com/file.txt\", move_to_drive=False)<br><br>\n",
        "\n",
        "# List downloaded files<br>\n",
        "list_files()<br><br>\n",
        "\n",
        "# Clear downloads<br>\n",
        "clear_files()\n",
        "</code>\n",
        "</div>\n",
        "\"\"\"))\n",
        "\n",
        "print(\"üéâ Enhanced Mirror Bot initialized successfully!\")\n",
        "print(\"üìù Use the functions above to start mirroring files\")\n",
        "print(\"üöÄ Now with enhanced filename preservation!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}